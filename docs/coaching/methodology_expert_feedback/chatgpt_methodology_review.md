Expert Feedback on Resilio Training Methodology

Overview and General Assessment

The Resilio’s approach of combining proven training literature with a modern metrics layer is conceptually sound and aligns with how many coaches integrate science and practice. Classic sources (Daniels, Pfitzinger, Fitzgerald’s 80/20, FIRST) provide the qualitative structure – defining training zones, periodization phases, and intensity distribution – while metrics like CTL (chronic training load), ATL (acute training load), TSB (training stress balance), ACWR (acute:chronic workload ratio), and a readiness score offer a quantitative overlay to personalize and adjust training load. This hybrid model is sensible: the books give the “what and why” of training, and the metrics inform “how much and when.”

That said, it’s crucial to ensure the metrics are used appropriately. The methodology must guard against over-reliance on numbers at the expense of athlete self-awareness. As one expert coach notes, metrics like TSS/CTL can suffer from data noise and false precision, so successful coaching often emphasizes subjective feedback and simple load measures over chasing exact numbers ￼ ￼. The system should use metrics as guidelines rather than absolute rules, and communicate them in athlete-friendly terms (“fitness”, “fatigue”, etc.) rather than raw acronyms. Overall, the layering of metrics on top of established training principles is a strength of the system, but it requires careful calibration and communication.

Below, each major question and potential issue from the methodology draft is addressed in detail, with evidence-based recommendations. The feedback covers the validity of using CTL/ATL/TSB/ACWR for multi-sport athletes, the choice of thresholds and formulas, and how to simplify or prioritize metrics for clarity. Citations from coaching literature and sports science research are provided to support the recommendations.

Q1. Combining Book-Based Methodology with CTL/ATL/TSB/ACWR

Context: The training plan structure (workout types, intensities, periodization) comes from books like Daniels and Pfitzinger, but they do not use CTL/ATL/TSB/ACWR. The system adds those metrics on top to quantify training load and readiness.

Assessment: Using the metrics as a complementary layer is methodologically sound and common in practice. Many modern coaching platforms (TrainingPeaks, etc.) and coaches use concepts like CTL/ATL (often called “fitness” and “fatigue”) alongside traditional training plans ￼. The key is to keep a clear separation: the books inform the qualitative training content, and the metrics provide quantitative monitoring. This split is reasonable as long as the athlete-facing language remains intuitive. For example, instead of saying “your CTL is 45,” the coach could say “your current fitness level (42-day training load) is in the ‘Recreational’ range,” tying the metric to a concept of fitness capacity.

Recommendation: Option (A) – keep both layers but document and communicate their roles clearly – is the best approach. The books’ guidance ensures training is grounded in proven principles, and the metrics add personalization in volume and recovery. This combination is supported by coaches’ experiences: they often use objective load measures to adjust plans, without discarding the fundamental structure of periodized training. However, implement (C) as well: align metric terminology with familiar language. For instance, CTL can be referred to as “chronic load (fitness)” ￼, ATL as “acute load (fatigue)”, and TSB as “form or freshness.” This avoids burdening athletes with jargon.

There is no need to reduce reliance on metrics entirely (Option B), because there is sufficient sports-science evidence that load monitoring helps manage fatigue and injury risk ￼ ￼. In a multi-sport context, where intuition can be harder (different activities stressing the body in varied ways), metrics are especially useful to keep the training load in check. Just ensure that the AI coach uses these numbers as guides, not absolute directives, and always cross-checks with the athlete’s subjective feedback (how they feel). This hybrid approach is supported by the IOC consensus that monitoring training load (like ACWR) alongside traditional training plans can inform injury prevention ￼, as long as one remembers these metrics are guidelines, not ironclad rules ￼.

Q2. Minimum History Before Using CTL and ACWR in Decisions

Context: CTL (42-day EWMA) needs sufficient data to be meaningful. The system documents 12 weeks (~84 days) as a conservative minimum for “fully valid” CTL, even though mathematically 42 days is the time constant. ACWR is not computed until 28 days of data are available (since it needs 4 weeks of history). The question is how much history should be required before relying on these metrics for decisions like setting weekly volume or warning about injury risk.

Analysis: Requiring a solid history is wise, but 12 weeks might be more conservative than necessary. TrainingPeaks typically considers ~6 weeks enough to establish CTL trends, as 42 days is the period over which ~95% of CTL is accrued ￼. Eight to ten weeks of data might strike a balance: it covers a couple of mesocycles of training. However, for volume prescriptions, erring on the side of caution for novices is prudent. Beginners or athletes returning from a long break shouldn’t have their weekly mileage purely computed from a possibly unstable CTL. In those cases, recent weekly mileage itself (last 2–4 weeks average) is an important input ￼ ￼ – and indeed Pfitzinger’s guidance is to use recent mileage as a baseline for building volume.

For CTL-based volume guardrails: It’s reasonable to start using CTL after around 6 weeks of consistent training data, but treat 12 weeks as the point where CTL is truly solid. In practice, that could mean: from week 6 onward, the AI coach can use CTL to estimate safe training volume, but with an asterisk if <12 weeks data (e.g., “Your training load is still stabilizing, so we’ll be conservative”). For experienced athletes with prior data (even imported), CTL can be trusted sooner. For ACWR, the 28-day minimum is standard in research and should remain – in fact, the IOC consensus and studies required ~4 weeks of data to calculate a meaningful ACWR ￼ ￼. So (b) for ACWR: require at least 4 weeks (28 days) of load data before using it in any injury-risk messaging.

Differences by population: Yes, adjust expectations by experience. Beginners with very low training history should not see complex metrics early on – keep advice simple (“focus on consistent training; it’s too early to draw fitness trends”). For a well-trained athlete who imports past training, CTL/ATL can be used immediately. In all cases, if history is minimal, lean more on recent mileage progression limits (10% rule) and the athlete’s feedback, rather than CTL/ACWR.

On the “safe volume range” bands: The methodology’s CTL bands for km/week (e.g. CTL <20 → ~15–25 km/week) roughly align with practical experience for runners of those fitness levels. They don’t need to exactly match the CTL zone labels, because those zone labels (Beginner <20, etc.) are more granular. In fact, the safe volume ranges seem a bit conservative (e.g. CTL 20–35 suggesting 25–40 km/week) which is appropriate for safety. It’s fine that the band boundaries differ slightly (20 vs 35 vs 50) – those ranges can be seen as guardrail recommendations that incorporate not just CTL but also typical training volume for someone at that fitness. I would keep them as is, but clarify them. If anything, aligning CTL 40 with the transition from “Developing” to “Recreational” might make sense, but a 5 km difference is trivial. The current ranges appear intentional to avoid big jumps: they provide a stepping stone for someone going from CTL 18 (~20 km/week) up to CTL 30 (~35 km/week) safely.

Recommendation: (a) Use CTL-based volume guidance after ~6 weeks of data, but with extra caution until 12 weeks. (b) Use ACWR only after 28 days, as implemented. (c) Tailor to experience: new athletes get simpler, recent-load-based advice, experienced athletes get the full metric treatment sooner. (d) The safe-volume CTL bands are fine; ensure they’re communicated as suggested ranges with context (e.g., “Based on your current fitness (CTL ~25), a weekly run volume of ~30 km is appropriate”). Always cross-check with the athlete’s actual recent miles and subjective readiness before big changes.

Q3. Load Formula for Cross-Sport Combined Load (RPE-Based TSS)

Context: The system uses an RPE-based formula to calculate training load in “arbitrary units” akin to TSS. The formula load = Hours × (IF^2) × 100 uses an Intensity Factor (IF) derived from session RPE (1–10 scale mapped to 0.50–1.10). This mimics the TrainingPeaks TSS formula (which is hours × IF² × 100 for power-based sports). This combined load is used across all sports.

Assessment: Using an RPE-based TSS proxy is a pragmatic solution for multi-sport athletes who may not have power or pace zones for every activity. Sports science supports the use of Session RPE as a valid measure of training load across different modalities ￼. In fact, a well-known method by Foster (2001) is to multiply session RPE by duration (in minutes) to get a load score ￼. The system’s approach is essentially a scaled version of that, with a non-linear intensity weighting (squaring IF) to account for the disproportionate stress of higher intensities. This is similar in spirit to TRIMP or Banister’s approach where intensity has a bigger impact on stress than volume when near maximal efforts.

The formula seems appropriate if the RPE-to-IF mapping is calibrated well. Notably, RPE 8 = IF 1.0 means an RPE 8 session for 1 hour yields 100 load units, which corresponds to a threshold-level effort – that is logical (RPE 8 is roughly lactate threshold intensity, often defined as “hard but sustainable for ~1 hour”). RPE 10 = IF 1.10 yields 121 units/hour, meaning an all-out hour (which is practically impossible) would overshoot 100, which is fine for shorter very hard sessions. RPE 3 = IF 0.65 gives ~42 units/hour, which aligns with an easy effort. These are in the ballpark of common TSS values coaches see (e.g. a 1-hour easy run ~40–50 TSS, 1-hour race-pace run ~90–100 TSS).

One potential concern: RPE is subjective and can vary by sport and athlete. A runner and a cyclist might both call a session “RPE 7,” but if the cyclist has a well-calibrated power meter, that RPE 7 might correspond to a different physiological load than the runner’s. However, in absence of sport-specific data, RPE is the universal language. Research supports session-RPE as a reliable internal load measure, correlating with heart rate measures in many cases ￼. The methodology also smartly includes HR-based and pace-based estimates when available, which will refine the load calculation beyond just subjective rating.

Recommendation: The RPE-based TSS formula is appropriate to continue using, with a few caveats to communicate to users: (c) Let athletes know that load from other sports is estimated from effort and duration – e.g., “Your cycling and climbing sessions contribute to your load based on how long and how hard you felt you went.” Emphasize it’s an estimate of stress. If possible, encourage athletes to use objective measures when available (heart rate, power, pace) to refine these estimates, as the system already does.

Optionally, (b) one could simplify the calculation to the Foster method (RPE × minutes) for transparency, but that would make intensity count linearly instead of quadratically. The current approach is defensible because it matches the widely-used TSS model where intensity has a squared impact. I would stick with it, since it allows integration with the CTL/ATL framework seamlessly (which assumes TSS-like inputs).

In short, keep the RPE→IF→TSS approach. It is scientifically grounded and practically useful across sports ￼. Just ensure good documentation or even in-app education so athletes understand that e.g. a very hard 30-minute CrossFit (RPE 9) might rack up as much load as a moderate 60-minute run, which reflects the higher intensity. This will avoid confusion when they see load numbers.

Q4. Multi-Sport Systemic and Lower-Body Multipliers

Context: The system assigns each sport a “systemic” load multiplier (for overall fatigue/fitness effect) and a “lower-body” load multiplier (for leg muscle/joint strain). For example, a 1-hour run yields full 100% of its base load to both systemic and lower-body (multipliers 1.0/1.0). A 1-hour cycling might yield 85% systemic (0.85) but only 35% lower-body (0.35), since cycling is aerobically taxing but gentler on the legs compared to running. These values were set by internal reasoning, not direct research.

Assessment: There is no universally accepted quantitative table of cross-sport load equivalences – coaches and scientists mostly deal with this qualitatively. The chosen ranges in the system (e.g., cycling systemic 0.85, run 1.0; swimming systemic 0.70; strength 0.55, etc.) seem plausible and even in line with anecdotal coaching wisdom. For example, triathletes often find that a certain amount of bike training does not fatigue them as much as the same TSS of running. As one discussion noted, a 3-hour marathon (~270 run TSS) left an athlete sore for days, while a cycling session of similar TSS was comparatively easy to recover from ￼. Some experienced triathletes even suggested heuristics like “1 TSS point in running is worth ~2 TSS on the bike” in terms of fatigue ￼. The system’s multipliers reflect a similar idea: by giving cycling only ~35% of the lower-body impact of running, it acknowledges that, say, 100 TSS of cycling is easier on the legs than 100 TSS of running. Swimming’s very low lower-body multiplier (0.10) also makes sense – it’s mostly upper-body and non-weight-bearing.

On systemic load, the multipliers indicate how much each sport contributes to overall fitness (aerobic) development. Running is 1.0 by definition. Cycling at 0.85 suggests it’s slightly less efficient at building “whole-body fitness” per hour of equivalent effort, which might be arguable but not far-fetched. Swimming at 0.70 implies an hour of hard swimming yields less general aerobic benefit for running/cycling than an hour of running – again plausible, given swimming’s arm-centric nature and often lower sustained heart rates for some athletes. Strength training 0.55 systemic is hard to pin down, but since strength sessions have lots of rest and are anaerobic, they may not raise CTL (aerobic fitness) as much, which the low multiplier captures.

Published data: We don’t have precise studies giving these multipliers, but there is agreement that not all TSS is created equal across sports ￼ ￼. Joe Friel (triathlon coach) has noted that 50 TSS running “feels” harder than 50 TSS cycling – this is why some triathletes track separate CTL for each discipline. Since this engine merges them, these multipliers are a reasonable attempt to balance the contributions. In absence of formal consensus, they are within a sensible range.

Sports to be conservative with: The riskiest area is likely strength training and high-impact cross-training. A heavy leg day in the gym might deserve an even higher lower-body multiplier for certain athletes (the code does add +0.25 if “squats” etc. are mentioned). Plyometrics or HIIT classes might stress the legs more than the default 0.55/0.40. Also, trail running given 1.10 lower-body is logical due to downhill pounding. Climbing with 0.10 lower-body is low (mostly upper-body sport), so that’s fine. CrossFit at 0.75 systemic / 0.55 lower-body is hard to generalize because CrossFit workouts vary, but at least the system looks for keywords to adjust.

Recommendation: (a) The multipliers are plausible; keep them but remain open to adjustment as more data comes in. They are in line with the notion that running is the most stressful on the body per unit time ￼, with cycling next, then swimming, etc. (b) There’s no official published table to “align” with; the closest guidance is coaches’ personal rules of thumb ￼. One thing to consider is informing users that combined load is an approximation. Perhaps cite that different sports’ loads aren’t perfectly equivalent ￼, but the engine accounts for this by weighting them. Encourage athletes to give feedback: e.g., “If you feel the cross-training is taxing your legs more than expected, let’s adjust.” The system could learn individual differences over time (that would be ideal future refinement).

In summary, the chosen multipliers are a reasonable starting point. They reflect the consensus that running causes the most fatigue and injury risk per “unit” of training, cycling less so, swimming even less. No glaring issues in those specific numbers stand out, aside from the inherent uncertainty. Monitoring how athletes respond and possibly tweaking for edge cases (like very heavy strength-focused phases or an outlier sport like rowing, which isn’t listed) would be the way forward.

Q5. ACWR Thresholds (1.3 vs 1.5), Rolling vs EWMA, and Messaging

Context: The engine uses ACWR (acute:chronic workload ratio) calculated with a rolling 7-day sum divided by rolling 28-day average. Two thresholds are in play: ACWR >1.3 triggers a caution (“elevated” load) and >1.5 triggers high risk (“danger”). These values echo common literature: 0.8–1.3 “sweet spot” and >1.5 associated with higher injury risk ￼. The question is whether using both 1.3 and 1.5 is appropriate, if rolling is okay versus using the EWMA approach, and how to word the feedback.

Evidence: The origin of these thresholds comes from studies by Gabbett and colleagues. Indeed, an IOC consensus statement and other research indicate injury risk is minimized when ACWR is in ~0.8–1.3, and “substantially greater risk when ACWR exceeds 1.5” ￼. So having two thresholds makes sense: one to signal the athlete is exiting the safe zone (>1.3) and another to warn of a likely dangerous spike (>1.5). This two-tier approach is analogous to a yellow flag and a red flag.

For messaging, it’s important not to over-alarm the athlete at 1.3. I suggest wording around 1.3 like: “Your recent training load is higher than usual (ACWR ~1.3+). This is a rapid increase – be cautious and ensure adequate recovery.” Avoid using the word “injury” at 1.3; instead say “elevated load” or “load spike”. For >1.5, it is fair to mention injury risk more explicitly, since research backs that injuries tend to spike in that range ￼. Wording can be: “Your short-term load is extremely high relative to your base (ACWR >1.5). This significantly elevates injury risk – a recovery day or reduced intensity is strongly recommended.” It’s wise to contextualize by saying “studies show injury risk rises when short-term load is this high ￼, so we need to dial back.” In short, use 1.3 as an “Elevated – watch out” signal, and 1.5 as “High Risk – take action”.

Rolling vs EWMA: The choice of a rolling ratio (7d/28d) versus an EWMA-based ratio is debated in sports science. The rolling method is simpler and was used in many of the original ACWR studies (7-day acute, 4-week chronic) ￼. The EWMA method (Exponentially Weighted Moving Average) gives more weight to recent days and can be more sensitive ￼. In fact, some researchers argue EWMA-based ACWR correlates better with injury than the rolling average version ￼. The Outside article noted that a weighted approach might improve predictive power but requires more data (50 days to “warm up”) ￼. For this system, consistency with CTL/ATL (which are EWMA) could be conceptually nice – for example, one could define ACWR = ATL_7d / CTL_28d, both of which are already EWMA. That would smooth out abrupt jumps. However, the classic thresholds (1.3, 1.5) were defined on the rolling method, so switching to EWMA might necessitate recalibrating what “1.3” means. Since the user base likely doesn’t know the technical difference, it’s acceptable to stick to the rolling 7/28 ratio for now, as it is easily explained (“last week vs last month’s average”). The key is to apply it thoughtfully, not blindly.

The methodology should also acknowledge limitations noted by Shrier et al. (2020) and others: ACWR is a blunt tool. It doesn’t account for absolute load (a low-mileage runner can get a high ratio with small changes) ￼, nor distribution of load within a week ￼, nor differences between sports ￼. The engine partly addresses some of this (e.g., lower-body load for running specifics, intensity distribution, etc.), but it’s good to not treat ACWR as infallible. Gabbett himself cautioned that ACWR thresholds are guidelines, not rigid rules ￼. So the AI coach should treat ACWR readings as one factor, always cross-checking with how the athlete feels and other signs of overreach.

Recommendation: (a) Use two thresholds 1.3 and 1.5, as currently done. This aligns with literature (0.8–1.3 safe, >1.5 high risk, with 1.3–1.5 being a grey zone) ￼. At ACWR >1.3, flag it as a caution (“Your training load has jumped recently, let’s be careful”). At >1.5, flag as high risk (“You’re in the danger zone for injury from a load spike”). This two-level messaging prevents crying wolf; the athlete knows >1.5 is more serious.

(b) Retain the rolling 7d/28d formula unless there’s a move to recalibrate everything to EWMA. Rolling is understandable and was the basis for those threshold values. If anything, you might internally test an ATL/CTL ratio as well for curiosity, but it’s not necessary to switch. Just be aware of rolling ACWR’s quirks (e.g., coming off a taper into a race week will produce a high ratio – the coach should recognize context, as noted in the Outside piece ￼).

(c) Caveats in messaging: Emphasize that ACWR is one indicator. For example: “Keep in mind, this ratio doesn’t consider all factors (e.g., it’s a relative measure). We also look at your readiness and how you’re feeling.” Also, note that ACWR research was largely on team sports and high-level athletes; for an amateur runner or triathlete, it’s a guide, not a guarantee ￼. If the athlete is older or has a history of injury, be extra conservative even below 1.5. If the athlete is very low-mileage (ACWR can spike easily from a small increase), lean more on absolute changes (e.g., “you added 10km this week from 20km to 30km, which is +50% – that’s significant even if the ratio can be skewed at low volumes”).

In essence: the ACWR thresholds are fine and evidence-supported; use them with nuanced wording. Two levels of alert are better than one, and rolling ACWR is acceptable given its prevalence in existing guidelines.

Q6. TSB Ranges for Training vs. Race Readiness

Context: The system currently classifies TSB (fitness minus fatigue) into zones: Overreached (< –25), Productive (–25 to –10), Optimal (–10 to +5), Fresh (+5 to +15), and Peaked (≥ +15). It uses +5 to +15 as a “sweet spot” for feeling fresh and ready, including for hard workouts or races. However, some sources (like Joe Friel) have suggested that peak race performance often comes when TSB is higher, e.g. +15 to +25 on race day.

Analysis: The existing zones are mostly in line with common training folklore, except possibly the upper end. Friel’s guideline for tapering is often cited: arriving at a goal race with TSB around +20 (range +10 to +25) for best performance ￼. In other words, fairly high freshness is desired on race day, after shedding fatigue in the taper. The engine’s “Peaked” zone starts at +15 which is close, though it currently labels +15 and above as Peaked (and might implicitly treat too high TSB as detraining beyond a point). In practice, if someone shows TSB +25, it likely means they rested a lot – could be fine for an A-race, but if it’s not intentional, it might indicate lost fitness or an over-taper.

For daily training guidance, a TSB of +5 to +15 is indeed a good range to feel fresh but still carrying enough fitness. Many athletes report their legs feel best for intense training or tune-up races when TSB is slightly positive (say +5 or +10). Negative TSB means you’re carrying fatigue, which can be okay (even “Productive”) in a heavy training cycle but would hurt race performance if extreme.

To reconcile these: it would make sense to distinguish “Fresh for quality workouts” from “Truly peak race fresh.” The system could keep +5 to +15 as an indicator that the athlete is fresh enough to nail hard workouts or a lower-priority race. For a goal race, aiming a bit higher (perhaps +10 to +20) might maximize performance, especially for longer races. However, you wouldn’t want the athlete to always be in +20 territory during training – that would mean they aren’t training hard enough to generate fatigue/adaptation.

Recommendation: (a) Consider adjusting the labeling: use –10 to +5 as “Optimal training range” (or “Balanced”) where the athlete has a good equilibrium of fitness and fatigue – this is great for normal training weeks (some fatigue but not crushing). Use +5 to +15 as “Fresh” or “Ready for Intensity”, meaning the athlete is fresh enough to hit hard sessions or short-term peaks. Then define maybe +15 to +25 as “Peaked for Race”. This higher band reflects a short-term peak where fatigue is deeply shed. Above +25 could be labeled “Overly Fresh” or “Detraining Risk” to indicate the athlete might be losing fitness if they stay that high for long (e.g., an excessively long taper or post-illness comeback shows a very high TSB due to low recent load).

In practical terms, I would rename +5 to +15 from “Peaked” to “Fresh” or “Race-Ready,” and then say “Peak Performance Range” might be roughly +10 to +20 for goal events. The exact numbers can be fuzzy – different athletes race well at different freshness levels. But +20 is a common target for long endurance events (marathon, etc.) according to Friel’s TrainingPeaks guidelines ￼.

For sources, the TrainingPeaks help or Friel’s blog have indicated that many athletes set their tapers to hit about +15 to +25 TSB on race day. While I don’t have the exact line to cite here, it’s a known guideline. The engine can incorporate that by advising athletes during taper: e.g., “We aim to get your form to around +15 by race day – that indicates you’re fresh and ready to perform.” So yes, (b) add a separate notion of “peak race readiness” at a slightly higher TSB than the everyday “fresh” zone.

Summary: Use TSB < –25 to warn of overreaching, –25 to –10 as “productive fatigue” (training hard but not too hard), –10 to +5 as “optimal balance” (routine training state), +5 to +15 as “fresh” (good for key workouts or lower priority races), and something like +15 to +25 as “peak form” (ideal for race day, achieved after taper) ￼. Adjust the labels accordingly so the athlete understands that being +20 on race morning is intentional, whereas being +20 mid-training cycle might mean they backed off a lot. Aligning these ranges with Friel’s concept will enhance clarity for athletes who may have seen those discussions.

Q7. Readiness Score Design and Missing Subjective Data

Context: The readiness score is supposed to combine both objective metrics (TSB, recent load trend) and subjective data (sleep quality, soreness, mood, etc.) into a 0–100 scale that guides daily intensity. Currently, however, the implementation uses an “objective-only” formula: 30% from TSB and 35% from load trend (which measures how the last 3 days’ load compares to the last 7 days). Sleep and wellness are not yet integrated, so their weights are 0. The result is a readiness score mostly driven by whether the athlete is carrying fatigue (negative TSB) and whether they have recently ramped up or eased off training (load trend).

Assessment: A single readiness score can be useful for an at-a-glance recommendation, but it should be treated with care. No single number can fully capture an athlete’s readiness (as one review put it, no single tool can provide a complete picture of readiness or injury risk ￼). With that said, combining TSB and short-term load reductions/increases is a reasonable start. TSB already captures a lot about fatigue vs fitness, and the 3-day vs 7-day load trend captures acute freshness (for example, if the athlete took the last 2 days easy, the trend will boost readiness, whereas if they trained hard for 3 days straight, readiness will drop even if TSB hasn’t yet plummeted).

The intended full design (TSB 20%, trend 25%, sleep 25%, wellness 30%) is well-balanced, giving slightly more weight to subjective wellness. If/when subjective data are available, I’d recommend following that general idea because things like soreness or poor sleep can sometimes detect issues that metrics don’t. In the absence of those, the system currently gave a bit extra weight to TSB and trend (30% and 35%). These values (total 65%) imply the remaining 35% is effectively defaulting to “neutral” since sleep and wellness are zeroed out. Having TSB count for 30% instead of 20% isn’t too problematic – TSB is a decent indicator of recovery state. However, one might worry that the readiness score could be overly optimistic or pessimistic without subjective input. For example, an athlete could have a great TSB (high readiness objectively) but might feel terrible due to poor sleep or an impending illness – the current system would overestimate readiness. Conversely, an athlete could have a low TSB (after heavy training) but actually feel okay and motivated; without subjective input the readiness might be underestimated.

Confidence and capping: The methodology mentions a “confidence” level for readiness. It would be prudent to mark readiness as “low confidence” whenever subjective components are missing. Essentially, if we only have 65% of the intended inputs, we should be cautious about the score. One approach (option (i)) is to automatically flag the readiness score as lower confidence when it’s objective-only. Another approach (ii) is to cap the maximum readiness score if subjective data are missing – for instance, one could say “Without sleep/wellness data, we won’t ever show readiness above e.g. 80 or 90 out of 100, because we want to leave room for the unknown factors.” That could prevent giving a full “95 – Excellent” readiness rating on objective data alone.

From an expert perspective, (a) having a single combined readiness score is useful as a daily decision tool (go hard, go easy, or rest). Many systems use something similar (WHOOP’s recovery score, for example, combines HRV, sleep, etc. into one number). Coaches often do this intuitively each day by asking “How do you feel?” and checking fatigue – the score tries to automate that. So yes, it’s useful, but it must be interpreted with context.

Recommendations:
• Weights: When subjective data is available, the planned 20/25/25/30 (TSB/load/sleep/wellness) seems reasonable. It gives slightly more weight to how the athlete feels (wellness 30%) which matches the coaching wisdom that subjective feeling often trumps pure data ￼.
• Objective-only mode: The current 30% TSB, 35% trend (total 65%) is okay, but I would actually suggest not scaling them up to fill 100%. Instead, one could keep them at 20% and 25%, and assign the remaining 55% to “unknown” – effectively this means if no subjective data, the highest readiness might only calculate to 45 (if TSB and trend are perfect). That’s one extreme approach to enforce caution. A softer approach: keep the scaled weights but limit the maximum readiness level. For example, you could say “Without wellness and sleep info, we will not label you ‘Primed’ (>80) because we’re not certain – the highest you’ll see is ‘Ready’ (~75).” This corresponds to (ii) capping the score or adjusting confidence.
• Confidence flag: Definitely mark the readiness as “low confidence” whenever sleep/wellness are missing. Communicate this to the user: e.g., “Readiness 70 (moderate) – based on training data alone. Subjective factors (sleep, soreness) not reported, so interpret with caution.” This invites the athlete to reflect on their own feeling, essentially encouraging them to input those subjective measures if possible.

In summary, the readiness score is a useful synthesis metric. Use it, but explicitly downgrade its certainty when it’s based only on partial data. Encourage the athlete to contribute subjective ratings for a fuller picture. This ensures the AI coach doesn’t come across as overconfident in the number. And as always, readiness should be a conversation starter – if the score says “low,” the coach (AI) might ask the athlete a follow-up about how they feel, to validate the data. That combination will yield the best decision.

Q8. Safety Override: Forcing Rest When ACWR > 1.5 and Readiness < 35

Context: The system has one hard rule where it will automatically prescribe a rest day if the athlete’s ACWR is above 1.5 (meaning a large load spike) and their readiness score is below 35 (meaning they are in a very fatigued or poor state). This is essentially a built-in safety net to prevent an obviously dangerous situation (high external load spike + signs of low readiness) from continuing with hard training.

Assessment: This override rule is sensible and appropriate. It mirrors what any prudent coach would do: if an athlete has both a big jump in training load and is feeling exhausted or showing poor recovery (low readiness), it’s a recipe for injury or overtraining if they keep pushing. In such a scenario, even the most hardcore training plans would call for backing off. Given that the AI can present options in other cases, reserving a “no choice – you must rest” for this extreme combination is a good safety feature. It’s analogous to a coach flat-out refusing to let an athlete do a hard workout when they show up looking ill and mentioning they just doubled their mileage last week – any responsible coach would insist on rest.

Is the threshold exactly right? ACWR > 1.5 and Readiness < 35 translates to: the athlete’s last week’s load is 50% higher than their baseline, and their form/readiness is “very low” (the methodology labels <35 as “REST_RECOMMENDED”). That threshold makes sense – it means both an objective red flag and a subjective/overall red flag are triggered. If anything, one could argue it might be worth including other factors like recent injury flags or very low TSB, but the readiness <35 already would reflect a very low TSB or other issues.

One might consider if either ACWR or readiness alone should ever force rest. Typically, coaches wouldn’t force rest on a single metric alone:
• ACWR > 1.5 with high readiness could mean the athlete handled the spike surprisingly well (perhaps a sudden spike from low training because of a lot of cross-training, etc.). In that case, caution is still needed but maybe not mandatory rest – maybe a light day is enough.
• Readiness < 20 (extremely low) even with normal ACWR might indicate illness or severe fatigue – an AI coach might also force rest if the athlete says “I have a fever” (and indeed the system has illness flags that override readiness to min 15). So there are already overrides for illness/injury notes in the readiness logic.

Given these, the chosen combo (ACWR >1.5 and readiness <35) is appropriately strict. It will catch the cases where the athlete is both doing too much and feeling it badly.

Recommendation: (a) Yes, it’s appropriate to have a hard override in this scenario. The user should be informed gently (“Coach’s orders: today must be a rest day for safety”). The AI can explain: “Your recent training load has spiked (ACWR high) and your recovery is poor (readiness very low). This combo greatly raises injury risk, so the safest course is to rest.”

I would not remove this override; it’s a crucial guardian. In fact, this is consistent with research that when high load and poor recovery coincide, injury risk is compounded ￼ ￼. The system is effectively doing what a smart coach would: eliminating the option to do something risky.

If tweaking thresholds at all, one could argue for being even more protective: e.g. readiness <30 instead of 35, if we only want to catch the absolute worst cases. But <35 (“very low”) is already a state where the methodology itself said “force rest” ￼ ￼. ACWR >1.5 is likewise a well-known danger point. So the combination is fine. Perhaps ensure that the readiness <35 is after any illness/injury flag adjustment – if someone is sick (readiness forced to 15) and ACWR >1.5 by coincidence, they definitely must rest (which they likely would anyway due to illness).

So, (b) I support ACWR >1.5 and Readiness <35 as the rule. If anything, consider also an override if the athlete self-reports an injury (that might be outside this scope though – presumably the AI would not schedule training if the athlete says “I’m injured”). But that’s more on the conversation side.

In summary: keep this override. It is an important safety catch. Document it clearly so the athlete isn’t surprised: e.g., “If your stress is very high and you’re not recovered, we’ll insist you take a day off to prevent harm.” This aligns perfectly with coaching best practices, where athlete health comes first.

Q9. Two-Channel Lower-Body Gating for Multi-Sport Athletes

Context: The system tracks “lower-body load” (with those multipliers we discussed) and uses it to decide if the athlete’s legs are too fatigued to handle a run quality session or long run. The rule given is: sum of the last 2 days of lower-body load > 2.5 × CTL triggers a risk flag and suggestion to delay/downgrade the run. For example, if CTL is 40, then 2.5×40 = 100; if the athlete did 100+ lower-body load points in the last 48 hours (say a long hike and a hard bike ride), the system will warn against a hard run today.

Concept validity: This idea of accounting for non-running leg stress before a running day is very insightful. Coaches of multi-sport athletes do consider this qualitatively. For instance, if a triathlete has a hard bike workout the day before, a coach might avoid putting intense run intervals the next day because, while the aerobic systems might be fine, the leg muscles might be fatigued or at higher injury risk from cumulative stress. Another example: if someone did heavy squats (strength training), a smart coach would likely adjust the next day’s run (maybe keep it easy or shorter). So the concept of a separate lower-body stress index to gate running is supported by practical experience – it’s essentially what good coaches do when they look at the big picture of an athlete’s week. There might not be published papers on a “leg load threshold,” but it aligns with known principles of recovery and specificity: the muscles and tendons need time to recover from load, and different activities contribute to that load differently ￼ ￼.

Threshold formula (CTL × 2.5 over 2 days): This is a heuristic. CTL is an indicator of the athlete’s chronic capacity. Multiplying it by 2.5 for a 2-day sum roughly means “if you accumulate more than 1.25×CTL per day for two days straight, that’s too much.” Another way to see it: 2.5×CTL spread over 2 days is an average of 1.25×CTL per day. Since CTL itself is roughly an average daily load, 1.25×CTL means 25% more than your average. Two days at 125% of your normal load might be fine systemically, but if all that load hit your legs, it could spell trouble (especially running load). This seems like a reasonable bar. It would catch, say, someone who normally handles 50 load/day (CTL) doing ~125 load for two days – maybe they did a long run (like 2 hours moderate = ~100 load) and the next day a long bike (which at lower-body multiplier 0.35 might not add too much, but say they did squats too, etc.).

We should examine an edge: Suppose CTL is low, like 20 (beginner). 2.5×20 = 50. That means if over two days the beginner had 50 lower-body load, the system would warn. 50 lower-body load could be as little as a 1-hour easy run (RPE 3 gives 42 base, lower-body multiplier 1.0 yields ~42) plus maybe a short hike. That might be okay, but for a CTL 20 person, two “big” days back-to-back is indeed risky. So it fits the intuition that lower fit athletes have a lower threshold in absolute terms. For a high CTL athlete, CTL 80 means threshold 200 over 2 days – that’s quite high, but a very fit athlete might sometimes do back-to-back hard days that sum near that (e.g., two big workouts). Even then, the system would flag it, which might be prudent to avoid injury even in well-trained folks.

Window of 2 days: Why 2 days? Likely because we care about yesterday’s fatigue and the day before’s residual. Musculoskeletal fatigue can carry over 48 hours especially from heavy eccentric or strength work. Coaches often consider what was done in the last 48 hours when scheduling intense sessions. This is reasonable. Some would argue a 3-day window could be relevant too, but 2-day is a good compromise to catch immediate residual fatigue.

Better ways? An alternative could be to track something like a rolling 7-day lower-body load vs chronic, but that starts to resemble ACWR again. The unique need here is to catch short-term leg fatigue. Another approach: use soreness or wellness data specifically about legs. If an athlete says “my legs feel shot,” that’s an obvious flag. The system does scan descriptions for soreness flags, which then reduce readiness. That might already integrate – an athlete might write “quads sore” in a note, and the readiness gets capped at 25, for example. So the combination of subjective and this objective rule is robust.

In absence of subjective, a formula is needed. CTL scaling is a clever way to individualize it (a higher CTL athlete can likely handle more absolute leg load). 2.5×CTL seems arbitrary but not unreasonable. It could possibly be tuned: maybe 3.0×CTL for very resilient athletes or 2.0×CTL for masters or injury-prone, etc. But one can keep 2.5 as a base and adjust per athlete type in the future (e.g., a known injury-prone runner might get a stricter threshold).

Recommendation: (a) The concept is supported by coaching practice: definitely keep the two-channel model to gate run workouts based on recent leg stress. It’s an innovative feature that acknowledges that not all fatigue is reflected in the overall CTL/ATL – muscle-specific fatigue matters. I’m not aware of direct research quantifying “safe leg stress,” but it aligns with the principle of avoiding back-to-back hard efforts on the same muscles.

(b) The CTL-scaled threshold is a reasonable heuristic. It grows with the athlete’s fitness, which is logical (stronger athletes can handle more stress). If more data or experience accumulates, you might refine the multiplier (2.5). But until there’s evidence, 2.5 is fine. One could note that 2 days of load >2.5×CTL likely also means ACWR is high, so this trigger will often coincide with ACWR triggers. But not always – e.g., a lot of cycling can push ACWR moderately without as high lower-body impact. So it covers a slightly different angle.

(c) As for other ways to do it: One idea is to enforce a simple rule like “no high-intensity run if legs are sore from another activity.” The system already tries to catch that via the injury/soreness flags in notes. Another way: incorporate a recovery run or rest day after any exceptionally high lower-body load day. The AI could proactively schedule easy days after, say, a day where lower-body load > CTL \* X (like >1.5×CTL in one day). This is more of a prescriptive approach rather than reactive gating. But it’s essentially the same ethos.

In the absence of subjective soreness ratings, the current approach is as good as any. It quantifies something coaches intuit. I would stick with it, and just be transparent to the athlete: e.g., “We postponed your interval run because your legs have taken a beating in the last 48 hours relative to your usual training level. Let’s give them another day to recover.” Athletes will understand that logic.

Q10. Recovery Weeks: Link to Load Metrics or Calendar Only?

Context: The engine schedules every 4th week as a recovery week (~70% of the previous week’s volume, per Pfitzinger’s recommendations). Currently, this is done by plan design (calendar-based), not by dynamically checking CTL or fatigue metrics. The question is whether the system should also use CTL/ATL/TSB to adjust or verify recovery weeks – for example, ensuring CTL plateaus or TSB rises during that week – or if sticking to the planned down week is enough.

Assessment: Traditional periodization (as in Pfitzinger’s plans) uses a cyclic approach: 2–3 weeks up, 1 week down, regardless of metrics. This has worked for countless athletes. Not every athlete will respond exactly the same – some might need a down week sooner, others could push longer – but the 4-week cycle is a proven general template. Now, metrics could offer insights: if an athlete’s ATL is very high and TSB deeply negative after only 2 weeks, maybe a coach would insert a recovery week early. Conversely, if an athlete’s TSB is still positive after 3 hard weeks (perhaps the athlete is under-training or very well conditioned), the coach might think the “recovery week” could still be beneficial to consolidate gains or even be slightly less recovery-ish because the athlete isn’t very fatigued.

That said, one must be cautious in micromanaging periodization with metrics. Periodization is as much art as science, and often the recovery week is as much psychological as physiological – a planned breather that also prevents accumulating too much fatigue. The current plan of every 4th week at ~70% volume is a solid default. I wouldn’t override it purely because metrics say the athlete is fine; preemptively skipping recovery weeks can lead to accumulated fatigue that the metrics might not fully capture (or might capture too late, after the athlete is already feeling it).

However, using metrics to validate or adjust within the recovery week could be useful. For instance, during a recovery week, you expect CTL to level off or even drop slightly, and you expect TSB to climb toward positive. If by mid-week the athlete’s TSB is still very low (say they carried a lot of fatigue in, or did too much early in the week), the AI could remind them to truly take it easy. Or if ACWR somehow stays >1.0 in a “recovery” week, something’s off – maybe they substituted too much intense cross-training. The system could then intervene: “This week was supposed to be recovery, but your load hasn’t decreased as planned. Let’s ensure you back off so that you actually recover.”

So I would suggest a middle ground: use metrics to monitor recovery weeks, but not necessarily to decide when they occur. Calendar-based scheduling is fine for planning; metrics-based feedback can fine-tune execution. If an athlete adapts slower or faster, a coach might adjust on the fly (e.g., “you’re still very fatigued, take another easy week” or “you seem fresh, but let’s stick to the recovery plan to be safe”).

Additionally, tying recovery weeks to CTL trends could be done conceptually: a well-executed recovery week might result in a small drop in CTL (~maintained fitness) and a rise in TSB from negative toward zero or positive. The AI could use that to judge if the week was truly lighter. If not, it can warn the athlete that they didn’t really reduce load and should be careful.

Recommendation: (a) Calendar-based recovery weeks are sufficient as a foundation – keep implementing them every 3rd or 4th week depending on the plan. Do not rely on CTL/ATL to spontaneously schedule a recovery week, because doing so could confuse the athlete and disrupt the plan structure. The athlete likely expects the pattern from the start.

However, you can enhance this by a metric check:
• At the start of a recovery week, if the athlete’s TSB is extremely low (e.g., –30 or below), consider extending the recovery or extra rest days because they are quite overreached (the AI could say “we may need a bit more recovery than normal because you’re very fatigued”).
• Conversely, if the athlete’s TSB is only slightly negative or already positive entering a recovery week (maybe the prior weeks were lower volume or the athlete is a quick adapter), you still do the recovery week, but you might allow a bit more moderate activity if the athlete feels good. Not volume-wise, but maybe a mild tempo run could be okay if it’s a high-level athlete. In general though, even if they feel good, a down week won’t hurt – it can be used for extra technique focus, etc. So probably still stick to reducing volume as plan says.

So (b) I’d implement simple guardrails for recovery weeks: e.g., “Ensure this week’s volume is at most 70% of last week” (which you already plan) and “avoid any intense sessions unless perhaps a very short one to maintain feel (which Pfitzinger often includes strides or light workouts in recovery weeks).” If an athlete somehow ends up ramping CTL during a recovery week (meaning they accidentally did more load than before – perhaps through other sports), flag that gently: “This was supposed to be easier, but your training load didn’t drop. Make sure you’re actually recovering.”

In summary, calendar-based recovery weeks are fine, as per literature. Use metrics as a feedback tool: they can confirm the athlete is shedding fatigue. If metrics show they aren’t, adjust the week (e.g., force additional rest or cut a session). If metrics show they have tons of headroom, resist the temptation to cancel the recovery week – consistency and prevention are key, and often an athlete who “feels fine” only realizes the value of a recovery week after taking it and then hitting new highs in the next block.

Q11. Too Many Metrics? Cognitive Load and Decision Quality for the AI Coach

Context: The system provides a lot of numerical indicators to the AI coach: CTL, ATL, CTL trend, TSB (with zones), ACWR (with zones), readiness (score, level, confidence), intensity distribution (80/20 compliance), plus guardrail flags (long run too long, etc.) and specific triggers. The concern is that this plethora of data might overwhelm the AI (and the user if exposed), leading to inconsistent or overly complex recommendations.

Perspective: Human coaches vary in their use of data. Some elite coaches track numerous metrics (HRV, sleep, TSS, etc.), while others stick to a few key ones and the athlete’s subjective feedback. Importantly, coaches who do track many variables typically synthesize them into a simple decision – they don’t recite all metrics to the athlete daily. They use the data in the background to inform their coaching eye. The AI here has to do both the synthesis and the explanation. Too many metrics could lead to “analysis paralysis” or contradictory signals if not prioritized.

From an expert coach’s view, the most critical factors for day-to-day adjustments are: How is the athlete feeling (subjective readiness), Recent training load and recovery (objective), and Upcoming goals/workouts. Metrics like CTL (fitness) matter more for longer-term planning (are we building up appropriately?), whereas daily go/no-go decisions hinge on acute factors (fatigue, soreness, acute load spikes). So yes, I would say some metrics are more primary and others can be secondary context.

In the current system: There is already an implicit hierarchy:
• Safety triggers (like the override with ACWR and readiness, or serious injury/illness flags) come first – that’s good.
• Then presumably readiness level (which includes TSB and recent load) is next in guiding whether to do a hard workout.
• CTL and progression rates are more for plan design and big picture – the AI might mention them in weekly summaries or when adjusting goals (“Your fitness (CTL) is improving steadily, up 5 points this month – good job”).
• The 80/20 compliance is a weekly/biweekly check, not a daily decision-maker (except “you’ve done a lot of intensity already this week” which the AI might consider).
• Guardrails like “long run too long relative to weekly volume” should be caught at plan creation or when the user logs an unplanned extra-long run, etc., not something the AI has to “decide” – it’s more a feedback/warning.

So I suspect the system is already intended to use certain metrics in certain contexts, but the prompt to the AI might indeed list all these things and it has to decide. If the AI isn’t guided on priority, it could confuse itself or the user (imagine it saying: “Fitness is building, but form is optimal, though ACWR is elevated, readiness is moderate, intensity distribution is 78% low (which is okay), your long run was slightly over 30% of weekly volume, etc.” – that’s a lot of info for an amateur to digest).

Recommendation: (b) I do feel the number of metrics is on the high side for daily coaching of amateurs. The system should simplify the AI’s decision inputs or at least structure them hierarchically. I would identify the “core three or four” metrics:
• Readiness (with its factors) – encapsulates fatigue vs recovery.
• ACWR – captures recent load spikes for injury risk.
• CTL trend or weekly volume trend – to ensure long-term progression is on track (not necessarily something to mention daily, but to consider in planning).
• Possibly Intensity distribution (80/20) – but this is more of a weekly check to ensure they aren’t doing too much moderate/high intensity.

Everything else can be considered supporting detail. For example, TSB is part of readiness; ATL/CTL are implicit in those; lower-body load trigger is a specific flag for run sessions. The AI logic could be: safety first (injury or illness flags, extreme ACWR -> rest), then readiness (if low, suggest easier options), then consider scheduled workout vs intensity balance (if many hard sessions lately, maybe swap for easy). CTL (fitness) comes into play for long-term questions like “Can we increase your training or should we hold?”. Guardrails come into play when the athlete deviates or asks for exceptions.

I suggest implementing a more explicit decision tree: 1. Hard safety flags: injury, illness, extreme ACWR+low readiness -> enforce rest. 2. Moderate risk flags: ACWR >1.3, readiness low 35–50, TSB very negative, recent heavy leg load -> suggest altering today’s plan (e.g., do an easy run instead of intervals). 3. Planned workout appropriateness: Is today a hard day scheduled? If yes, are conditions fine (readiness adequate, not too soon after last hard day, legs fresh enough)? If yes, proceed with confidence. If no, offer a downgrade or rest. 4. Big picture context: Remind about 80/20 if they’ve done a lot of intensity already in the week; check if weekly mileage jump is within 10%; if an upcoming race, consider taper adjustments, etc. 5. Long-term: Occasionally note CTL (“fitness”) progression or stagnation to motivate or adjust volume over weeks, but this is not a daily decision point.

An explicit hierarchy like above would improve consistency. The AI’s prompts can be structured to first evaluate those primary things. This avoids one day the AI focusing on ACWR and the next day focusing on CTL trend and confusing the athlete.

Human coach analogy: As you asked, coaches who use a lot of data do synthesize it. The best approach here is to treat many metrics as “dashboard lights” – the AI coach checks them in the background, but only brings up the relevant ones to the athlete when needed. For instance, if 80/20 compliance is fine, no need to mention it. If it’s not, the AI can say, “By the way, this week you’ve done a bit more intense work than ideal (about 70% low intensity instead of 80%). Let’s make sure the next few days are easy.” Similarly, CTL doesn’t need daily mention, but weekly might: “Your fitness is steadily improving.” This selective surfacing will reduce info overload.

Therefore: Yes, reduce the cognitive load on the AI by internally prioritizing metrics, and simplify what is communicated to the athlete. Keep the full set available under the hood for analysis (it’s good the system is tracking all these), but design the AI’s reasoning to focus on a few key questions each time:
• “Is it safe to train hard or do I need to back off?” (Readiness, ACWR, leg load, recent intensity)
• “Is the athlete on track toward their goals?” (CTL trend, weekly mileage, performance indicators)
• “Are there any guideline violations I should note?” (80/20, long run %, etc., only mention if problematic).

This approach will mimic a good human coach’s behavior: they always ensure safety and recovery are under control, adjust as needed, and guide the athlete toward the long-term plan, mentioning big picture load only when relevant. By doing this, the AI’s advice will come across as focused and coherent, rather than a scatter of metrics.

Q12. Risk Aggregation: Additive Weights and Bands

Context: The system computes an overall injury risk score by adding up weights for each trigger (ACWR high, readiness low, TSB overreached, etc.). For example, ACWR >1.5 contributes 0.40, readiness <35 adds 0.25, TSB < –25 adds 0.20, etc. The sum is converted to a risk level (Low/Moderate/High/Danger) with thresholds 0.20, 0.40, 0.60. This is a heuristic to combine multiple risk factors.

Assessment: In principle, an additive model is a straightforward way to combine factors. Each factor weight reflects how strongly it correlates with injury risk. The weights given actually seem to mirror a reasonable prioritization: a dangerously high ACWR is the biggest single contributor (0.40), which can instantly push risk into “High” zone even if nothing else is wrong – that makes sense given evidence tying high load spikes to injury ￼. Readiness being very low (likely indicating high fatigue or illness) is next significant (0.25). These could combine to cross 0.60 (Danger). This aligns with the earlier override logic: ACWR 0.40 + readiness 0.25 = 0.65, Danger. Lower-body load and TSB are smaller factors (0.20–0.25 each), which seems reasonable – a negative TSB alone of –30 (overreached) at 0.20 weight wouldn’t flag high risk unless accompanied by something else. That matches reality: some athletes purposefully overreach then recover (planned heavy training block); overreaching alone isn’t acute injury risk unless the athlete also has other risk factors.

The additive approach is okay given we don’t have a complex model (like machine learning or logistic regression probabilities). It’s transparent: if multiple moderate issues, they sum up. It might overestimate risk if factors overlap (some correlation exists between, say, ACWR and TSB usually), but the weights are conservative enough that overlap won’t push it to extreme unless it truly is an extreme scenario (which then likely merits a high risk label anyway).

Relative weights: ACWR >1.5 at 0.40 stands out as the largest, which I agree with – load spikes are strongly linked to injury in studies ￼. Readiness <35 (0.25) accounts for general fatigue/poor recovery – also important, though perhaps not as quantifiable in literature, it’s a broader catch-all for things like soreness, poor sleep, which do relate to injury risk. Lower-body load high (last 2 days) at 0.25 is interesting – it’s on par with readiness low. That might be slightly high or maybe okay; it basically is a specific case of overloading legs, which indeed could be a direct injury precursor (e.g., two heavy leg days can lead to injury even if ACWR weekly isn’t high). I might have weighted TSB < –25 a bit lower than 0.20 if readiness is already accounting for fatigue, but 0.20 is fine.

Bands 0.2/0.4/0.6: These thresholds produce a “Moderate risk” if the score is ≥0.20. That means any single trigger of medium weight will at least give moderate. For example, readiness <50 (if that had 0.15 weight) plus maybe something small could hit 0.20. Actually, readiness <50 was 0.20 weight in code per the doc, I think. If readiness is 45, that might add 0.20, hitting Moderate risk. That seems a bit sensitive – an athlete slightly tired gets “moderate injury risk”? However, moderate risk in this context likely just means the AI will advise caution; that’s not necessarily alarming. High risk (≥0.40) would require either one major factor or multiple factors. Danger (≥0.60) needs at least two significant ones. This scheme is reasonable to stratify advice:
• Low: carry on normally.
• Moderate: note some concerns (maybe suggest an easier option but leave it up to athlete).
• High: strongly suggest changes (perhaps recommend an easier training or extra rest).
• Danger: likely trigger the override or at least a very strong recommendation.

This approach is fine as a heuristic. It’s similar to how a coach’s mind might tally things: “You ramped up load (big risk) + you’re feeling worn out (another risk) => I’m very concerned (danger).” Or “You’re a bit tired and did a tad more than usual, that’s a moderate concern; we’ll adjust a bit.”

Alternatives: One could design logical rules (e.g., “if ACWR >1.5 AND readiness low, then Danger” etc., basically what we have done, but more explicit). The additive method allows gradation when there are multiple smaller issues. A multiplicative model doesn’t make sense here because these risk factors aren’t independent probabilities in a statistical sense – plus multiplicative would complicate interpretation. Additive is fine for conveying “stacking” of risk factors.

One caution: Summing to give a “probability %” as min(100, score\*100) might be misleading. If risk_score 0.60 means “Danger,” labeling it as “60% probability of injury” could scare athletes and is not actually evidence-based (actual injury probability in a given week even under bad conditions is usually much lower) ￼. It might be better to just present it as a qualitative level rather than a literal percent chance (unless you clearly say it’s not a precise probability). Since this is internal or for AI reasoning, it’s probably fine. But if athletes see “injury probability 60%,” that could be problematic. I’d advise the AI to translate it into language (“high risk”) rather than numeric probability.

Recommendation: (a) The additive risk model is acceptable and likely the best practical solution here. It allows combining factors without over-complication. I would keep it. It mirrors multi-factor risk assessment approaches used in health (like additive risk scores for cardiac risk, etc., when you can’t do a full model).

(b) The relative weights seem plausible. ACWR being weighted highest is justified by research ￼. Readiness (with subjective components when available) being next makes sense since an athlete in a very fatigued or ill state is more vulnerable. The weights might be fine-tuned over time if you observe the AI being too jumpy or too lax. For instance, if athletes constantly get “High risk” warnings on moderate training loads because of small triggers adding up, you might reduce some weights. But initial values are reasonable.

(c) The bands 0.2, 0.4, 0.6 for Moderate/High/Danger also seem okay. They ensure even one serious issue (0.4) triggers High. To double-check: ACWR >1.5 (0.4) => High. Readiness <35 (0.25) alone => 0.25, which is above 0.20 so Moderate risk (which is fair, very low readiness should at least be moderate concern). ACWR 1.4 (0.30) + readiness 40 (0.15) = 0.45, High risk – that matches an intuition that a moderately big load spike plus somewhat low readiness is concerning. So yes, I wouldn’t change the cutoffs unless experience shows otherwise. They provide a graded warning system.

In conclusion, the risk scoring method is fine. The main point is to use it as a decision aid for the AI to prioritize interventions, and to communicate risk to the athlete in categorical terms (Low/Mod/High) with explanations rather than just numbers. The weights can be tweaked if needed, but they’re a decent starting point.

Q13. 80/20 Intensity Distribution: Compliance Threshold and When to Apply

Context: The engine calculates the percentage of training time spent in low intensity vs moderate/high. It considers a week compliant with 80/20 if ≥75% of training minutes are low intensity, even though the “target” is 80%. Also, it currently calculates this for any week of training, though the methodology suggests only applying the strict 80/20 rule when the athlete is running at least 3 times per week (as per Fitzgerald, fewer runs make 80/20 less meaningful).

Analysis: Setting the compliance threshold at 75% (rather than 80% exactly) is a pragmatic decision. Real-world training can fluctuate; hitting exactly 80% every week isn’t necessary. Matt Fitzgerald’s own stance is to avoid the “moderate-intensity rut” and keep roughly 4:1 ratio of easy to hard minutes ￼. If an athlete hits 75%, that is still a 3:1 ratio – close enough for government work. A single week with 75% low, 25% higher intensity is not likely to be harmful, as long as over time they gravitate around 80/20. By allowing 75% as “compliant,” the system avoids over-flagging minor deviations. It’s similar to saying “Aim for 80/20, but anywhere above ~75% low is acceptable.” This leniency is good because intensity distribution can be a bit imprecise to measure (depends on how you classify each session, etc.). So (a) 75% threshold is reasonable. It gives the athlete a buffer. Perhaps internally the target remains 80%, but you only warn them if they drop below 75%. That’s similar to how some coaches might say “keep at least 3 out of 4 runs easy” (which is 75%) knowing that in practice that’s fine.

Now, regarding (b) when to apply 80/20: Fitzgerald explicitly notes that the 80/20 rule is most relevant when you have a decent volume of training. In 80/20 Running, he advises a minimum frequency of three runs per week (even if doing cross-training) to benefit from a polarized approach ￼. If someone runs only 1–2 times a week, their intensity distribution on running alone is not very informative (e.g., 1 interval run + 1 easy run = 50% low, which “fails” 80/20, but that doesn’t mean their overall training intensity is wrong if they cross-train a lot of low intensity). For such athletes, it might be better to consider their total training intensity distribution across all activities, or just not emphasize 80/20 as a metric.

I would recommend that the 80/20 calculation be highlighted primarily for athletes doing at least ~3 runs/week or 3 cardio sessions/week. If someone is a strength athlete who runs twice, telling them about 80/20 might confuse them – their focus is different. For triathletes or multi-sport folks, one could try to combine all aerobic activities into an overall intensity distribution, but mixing sports might complicate defining “moderate” vs “high” (the engine currently classifies by session RPE or type, which it can do across sports theoretically). Fitzgerald’s principle could be generalized: 80% of all endurance training time low intensity. If the engine can classify other aerobic workouts similarly, it might present an overall intensity distribution.

However, the simplest is: only enforce the 80/20 rule strictly for those on a running-focused program (or doing enough run sessions). For others, still educate them about the concept (“make sure most of your training, even in other sports, is easy”), but don’t generate compliance warnings if they have few sessions.

Recommendation:
• Threshold at 75% is fine and I would keep it. You can always encourage 80% as the ideal, but treat ≥75% as meeting the guideline. This way, if someone has, say, 74%, you nudge them (“you’re slightly below the ideal intensity distribution; try adding a bit more easy volume or reducing intensity”). If they’re consistently at 60%, then clearly flag it as non-compliant.
• Apply when appropriate: Only calculate and display the intensity distribution when the data is meaningful. I suggest (b) implementing the Fitzgerald rule: if <3 runs in the week, either don’t show the 80/20 stat or show it with a caveat (“80/20 rule typically applies when running at least 3 times a week. You only ran 2 times, so take this with a grain of salt”). Alternatively, consider all endurance sessions (run, bike, swim, etc.) in the denominator. If someone did 2 runs and 3 bikes, the combined total sessions might be enough to talk about overall distribution of intensities. But combining cross-training minutes with running minutes might dilute the clarity since effort classification across sports is consistent (based on RPE) but the athlete might not expect it. Perhaps simplest: if run frequency <3, relax the requirement. Matt Fitzgerald himself says in triathlon, you should still aim for 80% low across all training, but he also says runners doing fewer runs per week (like on FIRST’s 3-run program) should ensure those runs are mostly quality since the volume is low – essentially FIRST plan violates 80/20 by design, but it compensates with cross-training.

So, (c) citing Fitzgerald: He emphasizes at least three runs per week to safely implement 80/20 ￼. The engine should align with that: enforce intensity distribution targets mainly for those training as runners or doing enough volume.

Finally, for a source on numeric cutoff: Fitzgerald didn’t give a “75% is okay” explicitly, but it’s implied that 80/20 is approximate (80, give or take a few percent). Stephen Seiler’s research on polarized training showed most elites around 80% ± a bit. So I think being a tad lenient is scientifically fine.

Summary: Keep the weekly intensity distribution check, using ≥75% low as “compliant (green light)” with a target of 80% (maybe mention “you hit ~77% low-intensity, close to the 80% goal, good job”). And only emphasize this metric when it’s relevant: for predominantly endurance-focused athletes with multiple sessions a week. If a person is on a hybrid plan with minimal endurance sessions, don’t overemphasize 80/20 – maybe instead focus on ensuring they don’t do all their limited cardio at high intensity (common mistake), but frame it differently (“even though you only run twice, make sure one of them is genuinely easy”).

This way, the athlete gets the benefit of the 80/20 principle without the system appearing pedantic or giving false “non-compliance” for edge cases.

⸻

Sources:
• Pfitzinger, Advanced Marathoning – guidelines on recovery weeks (every 3–4 weeks ~70% volume) and 10% rule ￼ ￼.
• Fitzgerald, 80/20 Running – polarized training philosophy and need for ≥3 runs/week for proper intensity distribution ￼ ￼.
• Gabbett et al., IOC Consensus 2016 – ACWR sweet spot 0.8–1.3 and risk >1.5 ￼.
• Shrier et al. 2020 – critique of ACWR (limitations of ratio, suggestion of EWMA) ￼.
• Triathlon coaching discussion – differences in perceived stress between run, bike, swim and lack of precise TSS conversion ￼ ￼.
• ScientificTriathlon (Mikael Eriksson) – caution against over-focusing on TSS and importance of subjective feedback ￼ ￼.
• Sedeaud et al. 2020 (Frontiers) – found no clear “sweet spot” in ACWR for injury in practice, highlighting need for comprehensive monitoring ￼ ￼.
